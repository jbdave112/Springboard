{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seinfeld Script Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Necessary Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import operator\n",
    "import argparse\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load text file\n",
    "text = (open(\"Seinfeld_Scripts.txt\").read())\n",
    "text=text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Characters 109410\n",
      "Number of distinct Characters 60\n"
     ]
    }
   ],
   "source": [
    "print('Number of Characters:', len(text))\n",
    "print('Number of distinct Characters:', len(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pleading 1\n",
      "haven 4\n",
      "speak 3\n",
      "topic 2\n",
      "angered 2\n",
      "openly 1\n",
      "drops 4\n",
      "unemployed 1\n",
      "fastidious 1\n",
      "works 3\n",
      "answer 3\n",
      "jumps 3\n",
      "mother 15\n",
      "tastes 1\n",
      "extra 1\n",
      "sitting 12\n",
      "square 2\n",
      "directs 2\n",
      "three 9\n",
      "clubs 3\n",
      "europe 1\n",
      "brings 1\n",
      "utter 1\n",
      "medium 2\n",
      "spoken 1\n",
      "instinct 4\n",
      "inseparable 1\n",
      "father 2\n",
      "newspaper 3\n",
      "writer 2\n",
      "prove 1\n",
      "paying 2\n",
      "gonna 46\n",
      "solid 1\n",
      "sarcasm 1\n",
      "leave 11\n",
      "denise 4\n",
      "sensing 1\n",
      "beautiful 5\n",
      "toons 1\n",
      "introduced 1\n",
      "overly 1\n",
      "heavy 1\n",
      "today 10\n",
      "regret 1\n",
      "pounding 1\n",
      "joins 1\n",
      "stare 1\n",
      "everyday 1\n",
      "answers 4\n",
      "kiddin 1\n",
      "interference 1\n",
      "sudden 2\n",
      "goodbye 2\n",
      "fighting 2\n",
      "through 18\n",
      "states 2\n",
      "walking 7\n",
      "reporter 2\n",
      "gazpacho 1\n",
      "junior 3\n",
      "lungs 1\n",
      "large 4\n",
      "excitement 1\n",
      "decide 3\n",
      "moving 12\n",
      "theatre 2\n",
      "highly 1\n",
      "nickelodeon 1\n",
      "points 4\n",
      "telling 2\n",
      "forefinger 1\n",
      "everybody 2\n",
      "discharge 1\n",
      "applicants 1\n",
      "collapses 1\n",
      "already 5\n",
      "japanese 3\n",
      "inspiration 1\n",
      "writing 2\n",
      "guest 2\n",
      "hostage 1\n",
      "sailing 1\n",
      "domain 4\n",
      "appearance 1\n",
      "discussion 3\n",
      "bought 3\n",
      "kinds 1\n",
      "fruit 2\n",
      "space 1\n",
      "apples 1\n",
      "morning 2\n",
      "number 2\n",
      "mention 2\n",
      "being 4\n",
      "absolutely 6\n",
      "burst 1\n",
      "letting 2\n",
      "following 1\n",
      "violently 2\n",
      "inconceivable 1\n",
      "should 17\n",
      "beach 8\n",
      "respond 1\n",
      "lyndon 1\n",
      "transferred 1\n",
      "suggesting 1\n",
      "informs 1\n",
      "within 2\n",
      "continue 2\n",
      "locked 1\n",
      "infamous 1\n",
      "shoulder 2\n",
      "cheerful 1\n",
      "important 3\n",
      "pulling 1\n",
      "breathless 2\n",
      "spotting 1\n",
      "strange 3\n",
      "comedian 1\n",
      "sipping 1\n",
      "manor 1\n",
      "impressed 2\n",
      "chamber 1\n",
      "movies 2\n",
      "beeping 4\n",
      "sleep 3\n",
      "moment 7\n",
      "stick 2\n",
      "building 4\n",
      "stepping 1\n",
      "inside 4\n",
      "joyce 20\n",
      "toughs 2\n",
      "testosterone 1\n",
      "those 14\n",
      "ropes 1\n",
      "includes 1\n",
      "personal 2\n",
      "figuring 1\n",
      "months 1\n",
      "scratch 1\n",
      "stress 1\n",
      "arrested 1\n",
      "uptown 1\n",
      "queen 2\n",
      "saturday 2\n",
      "waitress 4\n",
      "gauche 1\n",
      "fried 1\n",
      "appeared 3\n",
      "happens 3\n",
      "along 10\n",
      "newman 7\n",
      "toilet 1\n",
      "taking 5\n",
      "action 1\n",
      "suffer 1\n",
      "bulky 1\n",
      "movie 6\n",
      "putting 2\n",
      "stage 1\n",
      "mystery 1\n",
      "health 2\n",
      "enough 6\n",
      "green 1\n",
      "beached 1\n",
      "falls 3\n",
      "treating 1\n",
      "confines 2\n",
      "guard 1\n",
      "owner 1\n",
      "shirts 3\n",
      "noticed 1\n",
      "fascinating 1\n",
      "limousine 3\n",
      "playing 1\n",
      "basement 1\n",
      "sleeping 2\n",
      "discount 1\n",
      "bring 4\n",
      "return 2\n",
      "unfortunately 1\n",
      "obstruction 1\n",
      "tables 6\n",
      "experiences 1\n",
      "clock 4\n",
      "indian 2\n",
      "anymore 6\n",
      "flipping 1\n",
      "unlocks 1\n",
      "stunned 2\n",
      "pants 1\n",
      "johnson 1\n",
      "subject 1\n",
      "numbers 1\n",
      "awake 2\n",
      "fraying 1\n",
      "angle 2\n",
      "obviously 12\n",
      "month 1\n",
      "spying 1\n",
      "extraneous 1\n",
      "announces 1\n",
      "sharon 31\n",
      "counting 1\n",
      "friends 8\n",
      "goood 1\n",
      "about 55\n",
      "distress 1\n",
      "salad 5\n",
      "track 1\n",
      "became 1\n",
      "phone 30\n",
      "tired 1\n",
      "center 2\n",
      "garden 1\n",
      "investigate 1\n",
      "doesn 6\n",
      "talkin 5\n",
      "swings 1\n",
      "setting 16\n",
      "adding 2\n",
      "shuttle 1\n",
      "doubt 1\n",
      "sentence 2\n",
      "monitor 1\n",
      "things 19\n",
      "little 22\n",
      "sexual 1\n",
      "drove 3\n",
      "stern 2\n",
      "trunk 1\n",
      "gives 2\n",
      "picked 4\n",
      "batting 1\n",
      "mental 1\n",
      "shorts 3\n",
      "hello 16\n",
      "salmon 2\n",
      "ceiling 2\n",
      "emphasized 1\n",
      "geneva 1\n",
      "scent 2\n",
      "bread 6\n",
      "probably 4\n",
      "backing 1\n",
      "robbed 1\n",
      "casually 1\n",
      "hmmmm 1\n",
      "pluggin 1\n",
      "zipped 1\n",
      "personable 1\n",
      "opinion 1\n",
      "foreshadowing 1\n",
      "fantastic 2\n",
      "closet 1\n",
      "conversation 6\n",
      "heading 2\n",
      "broadway 2\n",
      "watching 3\n",
      "present 2\n",
      "ohhhhh 1\n",
      "awakening 1\n",
      "version 1\n",
      "confused 3\n",
      "tonight 8\n",
      "hungry 1\n",
      "promotion 3\n",
      "restless 2\n",
      "embraces 1\n",
      "other 30\n",
      "vincent 1\n",
      "squeaking 1\n",
      "exception 1\n",
      "holmes 1\n",
      "rocky 1\n",
      "assistant 2\n",
      "honor 1\n",
      "attention 6\n",
      "islands 2\n",
      "financial 1\n",
      "organizer 15\n",
      "years 3\n",
      "press 1\n",
      "amazed 1\n",
      "mouths 1\n",
      "minute 5\n",
      "fails 1\n",
      "missed 3\n",
      "laundry 3\n",
      "smashed 1\n",
      "epileptic 1\n",
      "sherlock 2\n",
      "stance 1\n",
      "stifling 1\n",
      "cancelled 2\n",
      "needs 1\n",
      "remember 4\n",
      "range 1\n",
      "oughtta 1\n",
      "traction 1\n",
      "alright 26\n",
      "slaps 3\n",
      "livin 1\n",
      "wonders 1\n",
      "certain 1\n",
      "having 4\n",
      "downtown 2\n",
      "normal 1\n",
      "thieves 1\n",
      "weren 2\n",
      "lobby 1\n",
      "disappointed 2\n",
      "daring 1\n",
      "shuts 3\n",
      "snaps 1\n",
      "poker 1\n",
      "company 2\n",
      "retreats 1\n",
      "reflecting 2\n",
      "bellow 1\n",
      "flips 1\n",
      "knocking 1\n",
      "level 1\n",
      "shaking 1\n",
      "octopus 1\n",
      "world 5\n",
      "tommorrow 1\n",
      "raving 1\n",
      "insulting 1\n",
      "pleasure 1\n",
      "knock 2\n",
      "itching 1\n",
      "candy 1\n",
      "oranges 1\n",
      "largest 1\n",
      "insisting 1\n",
      "estate 1\n",
      "woman 28\n",
      "coming 6\n",
      "bonkos 3\n",
      "worse 1\n",
      "bioflavenoids 1\n",
      "published 2\n",
      "clever 2\n",
      "emotional 1\n",
      "squeak 1\n",
      "sarcastic 2\n",
      "thanks 5\n",
      "forms 1\n",
      "steeped 1\n",
      "perfection 2\n",
      "intervention 1\n",
      "busting 3\n",
      "screaming 1\n",
      "curtain 2\n",
      "mugged 1\n",
      "workin 1\n",
      "questions 1\n",
      "forgiven 1\n",
      "babying 2\n",
      "school 2\n",
      "helluva 1\n",
      "final 3\n",
      "bavarian 2\n",
      "moorrrnninng 1\n",
      "cleanliness 1\n",
      "kinda 4\n",
      "rachel 8\n",
      "praise 1\n",
      "theater 8\n",
      "sayin 2\n",
      "compliments 1\n",
      "scream 1\n",
      "aaaah 1\n",
      "outside 7\n",
      "argentina 1\n",
      "dolls 5\n",
      "blubber 1\n",
      "explanation 1\n",
      "walls 1\n",
      "handle 3\n",
      "evening 2\n",
      "showered 1\n",
      "biologist 9\n",
      "chewing 1\n",
      "click 14\n",
      "creep 1\n",
      "enters 15\n",
      "wholesome 1\n",
      "herself 2\n",
      "quizzically 1\n",
      "pinkie 2\n",
      "brazenly 1\n",
      "relieved 1\n",
      "finished 1\n",
      "closely 1\n",
      "furniture 2\n",
      "declaring 1\n",
      "donny 1\n",
      "suppose 1\n",
      "women 6\n",
      "sheila 25\n",
      "misses 1\n",
      "until 1\n",
      "journal 1\n",
      "spoke 1\n",
      "composure 1\n",
      "become 4\n",
      "cruise 1\n",
      "comedy 1\n",
      "balls 1\n",
      "tries 1\n",
      "judgment 1\n",
      "pushed 1\n",
      "fliers 1\n",
      "story 10\n",
      "partnership 1\n",
      "vitamin 1\n",
      "light 4\n",
      "except 1\n",
      "remembers 1\n",
      "regis 19\n",
      "companions 1\n",
      "thank 15\n",
      "specializing 1\n",
      "costanza 5\n",
      "captured 1\n",
      "dating 3\n",
      "counter 6\n",
      "sometimes 1\n",
      "either 1\n",
      "progress 1\n",
      "heard 11\n",
      "flaunt 1\n",
      "makes 8\n",
      "ready 4\n",
      "signing 2\n",
      "pencil 1\n",
      "grabs 4\n",
      "sandwich 1\n",
      "instant 1\n",
      "chair 8\n",
      "reached 1\n",
      "unable 3\n",
      "television 2\n",
      "problem 7\n",
      "covers 1\n",
      "really 36\n",
      "persistent 2\n",
      "everywhere 3\n",
      "chuckling 1\n",
      "break 3\n",
      "exactly 2\n",
      "private 2\n",
      "notion 1\n",
      "bigger 1\n",
      "bickering 2\n",
      "feature 1\n",
      "kisses 2\n",
      "unpacking 1\n",
      "windows 1\n",
      "parts 1\n",
      "experience 1\n",
      "purse 6\n",
      "jarmal 2\n",
      "lavish 1\n",
      "excuse 5\n",
      "explains 1\n",
      "explain 1\n",
      "living 5\n",
      "convinces 1\n",
      "pardon 1\n",
      "titleists 1\n",
      "colony 1\n",
      "store 1\n",
      "figured 2\n",
      "hostile 1\n",
      "usual 1\n",
      "unbelievable 3\n",
      "giddy 1\n",
      "grabbed 1\n",
      "discreetly 1\n",
      "respect 2\n",
      "front 11\n",
      "wanna 13\n",
      "shmmopy 1\n",
      "minding 1\n",
      "guess 11\n",
      "flagg 1\n",
      "oozes 1\n",
      "automatic 1\n",
      "hulking 1\n",
      "films 1\n",
      "innocent 1\n",
      "switch 1\n",
      "replies 1\n",
      "reason 5\n",
      "sweet 2\n",
      "swear 1\n",
      "locker 1\n",
      "magazine 4\n",
      "comfortable 1\n",
      "journalism 1\n",
      "differ 1\n",
      "lifetime 1\n",
      "homosexuals 1\n",
      "receipt 1\n",
      "engaged 1\n",
      "stands 1\n",
      "breaks 1\n",
      "recruit 1\n",
      "department 1\n",
      "feelings 1\n",
      "double 1\n",
      "champagne 1\n",
      "shake 3\n",
      "exchange 2\n",
      "complete 2\n",
      "girlie 1\n",
      "kathy 18\n",
      "priority 1\n",
      "benefit 2\n",
      "seinfeld 4\n",
      "everyone 7\n",
      "ocean 3\n",
      "eavesdropping 3\n",
      "whaddya 2\n",
      "timed 1\n",
      "starting 1\n",
      "eating 4\n",
      "interpreter 1\n",
      "screams 2\n",
      "pretend 1\n",
      "proudly 1\n",
      "hurry 1\n",
      "fixed 1\n",
      "awaiting 1\n",
      "spirit 1\n",
      "confront 2\n",
      "gimme 2\n",
      "stripe 1\n",
      "coffin 1\n",
      "sneaks 1\n",
      "everything 6\n",
      "nothin 1\n",
      "reading 2\n",
      "disbelief 1\n",
      "jewel 3\n",
      "yankees 7\n",
      "mammal 3\n",
      "piece 6\n",
      "quarters 1\n",
      "advantage 1\n",
      "marine 11\n",
      "sunbeams 1\n",
      "jerry 581\n",
      "matsushimi 2\n",
      "start 2\n",
      "leafing 1\n",
      "stroke 1\n",
      "there 89\n",
      "smiles 2\n",
      "wrong 13\n",
      "collected 1\n",
      "parsley 1\n",
      "shave 2\n",
      "balance 2\n",
      "bania 7\n",
      "algae 1\n",
      "watched 2\n",
      "wasting 1\n",
      "message 2\n",
      "bisque 3\n",
      "loopy 1\n",
      "thick 1\n",
      "skiing 2\n",
      "aware 1\n",
      "neighborhood 1\n",
      "turning 3\n",
      "bette 1\n",
      "expressing 1\n",
      "against 2\n",
      "thief 3\n",
      "helped 1\n",
      "illness 1\n",
      "messiah 1\n",
      "sonia 2\n",
      "alone 4\n",
      "tolstoy 5\n",
      "knocks 1\n",
      "dances 1\n",
      "typical 1\n",
      "picks 5\n",
      "silhouette 2\n",
      "bursts 1\n",
      "aside 1\n",
      "mentally 1\n",
      "waiting 3\n",
      "wearing 1\n",
      "arrange 1\n",
      "artisans 1\n",
      "longer 2\n",
      "himself 2\n",
      "college 1\n",
      "impression 5\n",
      "waitin 1\n",
      "woolight 1\n",
      "seeing 1\n",
      "successful 1\n",
      "ordered 1\n",
      "notice 2\n",
      "fella 1\n",
      "happened 11\n",
      "chowder 1\n",
      "touch 2\n",
      "neither 1\n",
      "lifted 1\n",
      "refused 1\n",
      "hopefully 1\n",
      "closes 1\n",
      "picture 2\n",
      "dunes 1\n",
      "somebody 5\n",
      "doors 1\n",
      "jehova 1\n",
      "begin 3\n",
      "knowing 1\n",
      "converge 1\n",
      "slowly 7\n",
      "understand 5\n",
      "tongue 4\n",
      "speed 1\n",
      "service 1\n",
      "stadium 2\n",
      "george 414\n",
      "architecture 1\n",
      "pulls 5\n",
      "snorts 2\n",
      "glance 1\n",
      "mistress 2\n",
      "comprehens 1\n",
      "covering 1\n",
      "contest 6\n",
      "undertake 1\n",
      "addresses 3\n",
      "words 1\n",
      "modern 1\n",
      "later 10\n",
      "stolen 1\n",
      "talked 3\n",
      "every 15\n",
      "listen 12\n",
      "yankee 2\n",
      "wheels 2\n",
      "beloved 1\n",
      "million 1\n",
      "finish 1\n",
      "favor 2\n",
      "rings 3\n",
      "porcine 2\n",
      "americans 1\n",
      "draft 1\n",
      "related 1\n",
      "deeply 1\n",
      "unknown 1\n",
      "attorney 1\n",
      "definitely 1\n",
      "title 3\n",
      "businessmen 1\n",
      "degaulle 2\n",
      "master 4\n",
      "mulligatawny 3\n",
      "table 20\n",
      "nearly 1\n",
      "looks 17\n",
      "moire 1\n",
      "disbelievingly 1\n",
      "welcome 2\n",
      "takes 15\n",
      "decided 2\n",
      "standing 7\n",
      "sarcastically 1\n",
      "grouchy 1\n",
      "stuff 2\n",
      "plans 1\n",
      "holds 2\n",
      "impress 1\n",
      "shmoopies 1\n",
      "colonies 1\n",
      "hands 2\n",
      "happening 5\n",
      "beauty 1\n",
      "beside 2\n",
      "trying 16\n",
      "fingers 2\n",
      "excited 10\n",
      "rules 2\n",
      "prints 1\n",
      "likes 1\n",
      "relive 1\n",
      "trusted 1\n",
      "turkish 1\n",
      "blank 1\n",
      "tolerate 1\n",
      "lapels 1\n",
      "canadian 1\n",
      "united 1\n",
      "asked 10\n",
      "bright 1\n",
      "couple 6\n",
      "maneuver 1\n",
      "french 2\n",
      "caught 7\n",
      "rinse 1\n",
      "convinced 1\n",
      "socks 7\n",
      "above 1\n",
      "mouthing 1\n",
      "throw 2\n",
      "twenty 6\n",
      "affectionate 1\n",
      "cheeseburger 1\n",
      "maybe 13\n",
      "thinks 5\n",
      "bills 3\n",
      "stopping 1\n",
      "freely 1\n",
      "escorted 1\n",
      "pieces 1\n",
      "joking 2\n",
      "deconn 4\n",
      "shadows 1\n",
      "divider 4\n",
      "smoking 1\n",
      "thoughts 1\n",
      "leanord 1\n",
      "drive 2\n",
      "looked 6\n",
      "laugh 3\n",
      "singing 1\n",
      "different 5\n",
      "beast 1\n",
      "somehow 1\n",
      "towards 2\n",
      "hanging 1\n",
      "forcibly 3\n",
      "meeting 4\n",
      "chopped 3\n",
      "reminding 1\n",
      "someone 8\n",
      "burning 1\n",
      "drink 2\n",
      "clavin 1\n",
      "looses 1\n",
      "muchacho 1\n",
      "notices 3\n",
      "goose 1\n",
      "however 1\n",
      "focused 1\n",
      "faint 2\n",
      "hangs 4\n",
      "muttering 1\n",
      "personally 1\n",
      "slipping 1\n",
      "dress 1\n",
      "seems 5\n",
      "alerts 1\n",
      "thirty 6\n",
      "mulling 1\n",
      "reaches 1\n",
      "collar 1\n",
      "forced 2\n",
      "gestures 1\n",
      "spanish 1\n",
      "together 9\n",
      "block 2\n",
      "recipe 2\n",
      "krmaer 1\n",
      "schedule 1\n",
      "these 16\n",
      "excitable 1\n",
      "course 10\n",
      "bucks 3\n",
      "berlin 1\n",
      "terminal 1\n",
      "caused 1\n",
      "calls 2\n",
      "girlfriend 1\n",
      "susan 17\n",
      "marla 26\n",
      "changing 1\n",
      "underwear 1\n",
      "masquerade 1\n",
      "tosses 1\n",
      "offers 1\n",
      "pocket 5\n",
      "alleys 1\n",
      "threw 5\n",
      "cream 2\n",
      "shadow 1\n",
      "reveals 2\n",
      "washed 3\n",
      "kicked 3\n",
      "wardrobe 1\n",
      "dining 2\n",
      "sense 3\n",
      "turtles 2\n",
      "chest 1\n",
      "humor 1\n",
      "figure 4\n",
      "mushrooms 2\n",
      "ahead 3\n",
      "alley 2\n",
      "defensively 1\n",
      "russian 2\n",
      "opposite 19\n",
      "between 4\n",
      "across 6\n",
      "shelly 5\n",
      "tickets 2\n",
      "threatened 1\n",
      "bombardier 1\n",
      "anyway 6\n",
      "alrighty 1\n",
      "growing 1\n",
      "order 4\n",
      "yesterday 4\n",
      "dilemma 1\n",
      "celery 2\n",
      "leader 1\n",
      "graceful 1\n",
      "think 47\n",
      "shifting 1\n",
      "going 42\n",
      "pictures 1\n",
      "nobody 4\n",
      "buddy 2\n",
      "ignoring 1\n",
      "caveat 1\n",
      "puffy 1\n",
      "belongs 1\n",
      "virgin 3\n",
      "dunno 3\n",
      "tragic 1\n",
      "homosexuality 1\n",
      "melancholy 1\n",
      "solutes 1\n",
      "reactions 1\n",
      "interested 4\n",
      "better 10\n",
      "biologists 1\n",
      "given 2\n",
      "frantic 1\n",
      "estelle 20\n",
      "close 6\n",
      "witnesses 1\n",
      "comes 10\n",
      "liked 1\n",
      "continues 1\n",
      "afternoon 2\n",
      "class 9\n",
      "gettin 1\n",
      "tryin 3\n",
      "thumb 1\n",
      "shaving 1\n",
      "separate 1\n",
      "consider 1\n",
      "proud 5\n",
      "whoop 1\n",
      "benes 1\n",
      "knows 4\n",
      "forgot 1\n",
      "bedroom 5\n",
      "window 19\n",
      "pause 3\n",
      "called 5\n",
      "deserve 1\n",
      "shocked 2\n",
      "insurance 1\n",
      "niece 1\n",
      "cranky 1\n",
      "christ 1\n",
      "direction 2\n",
      "extraordinarily 1\n",
      "supposed 3\n",
      "dawns 1\n",
      "ohhhh 1\n",
      "consoling 1\n",
      "approaches 1\n",
      "cancel 1\n",
      "cleaning 1\n",
      "barely 1\n",
      "realizes 2\n",
      "meanwhile 3\n",
      "gardeners 1\n",
      "promise 2\n",
      "interesting 1\n",
      "since 3\n",
      "shmoppy 1\n",
      "baseball 1\n",
      "purpose 1\n",
      "heavily 1\n",
      "pounds 2\n",
      "middle 2\n",
      "decision 2\n",
      "stupid 2\n",
      "exact 3\n",
      "electronic 2\n",
      "backwards 1\n",
      "right 65\n",
      "losing 1\n",
      "ashamed 2\n",
      "cahsier 1\n",
      "necessary 1\n",
      "flings 1\n",
      "radio 1\n",
      "wonderful 4\n",
      "noticing 1\n",
      "dimaggio 1\n",
      "lying 2\n",
      "defensive 1\n",
      "galapagos 2\n",
      "smiling 9\n",
      "callously 1\n",
      "terrorist 1\n",
      "thought 10\n",
      "lippman 30\n",
      "awful 2\n",
      "flying 1\n",
      "temperamental 1\n",
      "restaurant 1\n",
      "sunday 2\n",
      "checks 3\n",
      "stopped 1\n",
      "account 1\n",
      "resolves 1\n",
      "never 13\n",
      "couldn 10\n",
      "removing 1\n",
      "chained 1\n",
      "perceptive 1\n",
      "kissing 3\n",
      "hatchet 1\n",
      "state 1\n",
      "sidewalk 2\n",
      "maintain 1\n",
      "uneasy 1\n",
      "indignantly 1\n",
      "showing 2\n",
      "inquiry 1\n",
      "special 1\n",
      "machine 4\n",
      "butting 1\n",
      "birds 1\n",
      "stares 1\n",
      "booth 5\n",
      "parent 1\n",
      "using 1\n",
      "enter 3\n",
      "working 10\n",
      "forty 1\n",
      "glass 2\n",
      "massive 1\n",
      "place 10\n",
      "culottes 4\n",
      "kissed 1\n",
      "reneged 1\n",
      "sailor 1\n",
      "although 3\n",
      "shown 1\n",
      "dying 2\n",
      "regarding 1\n",
      "acting 1\n",
      "wouldn 10\n",
      "especially 1\n",
      "cousin 3\n",
      "waves 2\n",
      "doctor 1\n",
      "saved 1\n",
      "satisfaction 1\n",
      "throat 1\n",
      "castle 1\n",
      "while 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gayness 1\n",
      "pointing 5\n",
      "kennedy 7\n",
      "thighs 1\n",
      "complex 1\n",
      "happy 8\n",
      "swinging 1\n",
      "chuckles 3\n",
      "forward 4\n",
      "nothing 11\n",
      "ordering 2\n",
      "dumbest 1\n",
      "yours 2\n",
      "pilot 2\n",
      "noise 6\n",
      "eagerly 2\n",
      "outta 3\n",
      "companion 1\n",
      "sheet 1\n",
      "eaten 1\n",
      "attracted 2\n",
      "young 3\n",
      "though 4\n",
      "latest 3\n",
      "tossed 1\n",
      "anybody 2\n",
      "shift 2\n",
      "pulled 1\n",
      "slightly 4\n",
      "change 1\n",
      "garbage 1\n",
      "psyched 2\n",
      "mistake 3\n",
      "dinner 2\n",
      "sexuality 1\n",
      "appreciate 3\n",
      "opens 6\n",
      "porno 3\n",
      "academically 1\n",
      "residences 1\n",
      "handful 1\n",
      "brezhnev 1\n",
      "night 17\n",
      "colonel 1\n",
      "sister 1\n",
      "funny 3\n",
      "heroes 1\n",
      "screen 2\n",
      "shades 1\n",
      "making 10\n",
      "lately 3\n",
      "nasty 1\n",
      "dollars 3\n",
      "climbin 1\n",
      "laughing 6\n",
      "surprise 2\n",
      "train 1\n",
      "sickening 1\n",
      "quality 1\n",
      "dangerous 1\n",
      "recorder 7\n",
      "bottom 1\n",
      "upset 1\n",
      "pendman 1\n",
      "darlin 1\n",
      "scoffs 1\n",
      "position 1\n",
      "lucky 1\n",
      "hospital 13\n",
      "which 6\n",
      "answering 1\n",
      "investigation 1\n",
      "opening 1\n",
      "seinfled 1\n",
      "danny 1\n",
      "intercom 4\n",
      "factly 2\n",
      "settling 1\n",
      "papers 2\n",
      "pride 1\n",
      "truth 7\n",
      "versions 1\n",
      "fifty 4\n",
      "voice 5\n",
      "split 1\n",
      "changed 1\n",
      "attitude 1\n",
      "stinkin 1\n",
      "selling 1\n",
      "cushman 7\n",
      "caved 2\n",
      "buzzes 5\n",
      "religion 1\n",
      "tsate 1\n",
      "suposed 1\n",
      "interom 1\n",
      "uncomfortable 2\n",
      "point 7\n",
      "traps 1\n",
      "bluey 3\n",
      "before 13\n",
      "strangers 1\n",
      "plane 2\n",
      "killing 1\n",
      "stock 1\n",
      "skeptical 1\n",
      "corinne 18\n",
      "catches 1\n",
      "water 2\n",
      "injure 1\n",
      "customer 4\n",
      "would 27\n",
      "after 5\n",
      "streaming 1\n",
      "swiped 1\n",
      "current 1\n",
      "maids 1\n",
      "reduced 1\n",
      "goldenboy 2\n",
      "throws 6\n",
      "cushions 1\n",
      "wanted 7\n",
      "sympathy 1\n",
      "metropolitan 1\n",
      "staring 6\n",
      "accident 5\n",
      "tellin 3\n",
      "fabulous 4\n",
      "behind 10\n",
      "committed 1\n",
      "inspired 2\n",
      "eccentric 1\n",
      "gasps 4\n",
      "tried 1\n",
      "asking 1\n",
      "buckle 1\n",
      "chosen 1\n",
      "muligatawny 1\n",
      "cholesterol 1\n",
      "found 4\n",
      "begins 1\n",
      "difficult 2\n",
      "yells 2\n",
      "squeals 1\n",
      "again 24\n",
      "climb 1\n",
      "laughter 1\n",
      "shared 1\n",
      "almost 3\n",
      "disgusting 2\n",
      "serious 3\n",
      "breath 4\n",
      "sorry 13\n",
      "usually 1\n",
      "knees 1\n",
      "glamour 3\n",
      "turkey 1\n",
      "situation 3\n",
      "passed 1\n",
      "instead 3\n",
      "possibly 1\n",
      "common 1\n",
      "washing 1\n",
      "popcorn 1\n",
      "thousand 1\n",
      "finally 2\n",
      "adios 1\n",
      "antique 2\n",
      "referred 1\n",
      "lowering 1\n",
      "raises 1\n",
      "diner 3\n",
      "amazing 2\n",
      "processing 3\n",
      "bother 1\n",
      "easiest 1\n",
      "clicks 1\n",
      "philosophical 1\n",
      "hissy 1\n",
      "appointments 2\n",
      "astonishment 1\n",
      "searches 1\n",
      "placed 1\n",
      "house 10\n",
      "shirt 6\n",
      "manager 6\n",
      "patient 4\n",
      "yelling 3\n",
      "giving 2\n",
      "jacket 5\n",
      "queries 1\n",
      "brown 2\n",
      "atmosphere 1\n",
      "afraid 3\n",
      "dropped 3\n",
      "steam 2\n",
      "musical 1\n",
      "helen 1\n",
      "please 21\n",
      "windowsill 1\n",
      "entertainment 1\n",
      "coffee 33\n",
      "bangs 1\n",
      "holding 1\n",
      "remembered 2\n",
      "paper 6\n",
      "curious 1\n",
      "stack 1\n",
      "talking 19\n",
      "architect 2\n",
      "smacks 1\n",
      "broke 2\n",
      "pushing 1\n",
      "pleas 1\n",
      "episode 2\n",
      "applaud 1\n",
      "allison 20\n",
      "kitchen 1\n",
      "salutations 1\n",
      "dismisses 1\n",
      "accent 1\n",
      "simmered 1\n",
      "scott 1\n",
      "peace 4\n",
      "troops 1\n",
      "money 14\n",
      "essentially 1\n",
      "dream 3\n",
      "presses 1\n",
      "thursday 1\n",
      "thinking 3\n",
      "cunks 1\n",
      "ecstatic 1\n",
      "refuses 2\n",
      "steinbrenner 3\n",
      "shhhhh 1\n",
      "panting 1\n",
      "question 9\n",
      "bellhops 1\n",
      "eight 1\n",
      "amusement 1\n",
      "always 14\n",
      "communicate 1\n",
      "pitch 1\n",
      "raise 1\n",
      "leonard 1\n",
      "business 4\n",
      "chance 4\n",
      "manuscript 1\n",
      "watch 5\n",
      "tears 1\n",
      "struggling 1\n",
      "thing 28\n",
      "gorgeous 3\n",
      "beggin 1\n",
      "perverted 1\n",
      "skidded 1\n",
      "remind 1\n",
      "brief 2\n",
      "complaints 1\n",
      "whale 6\n",
      "finding 1\n",
      "fatale 1\n",
      "turnoff 1\n",
      "plays 1\n",
      "notes 2\n",
      "great 18\n",
      "airport 1\n",
      "enjoying 1\n",
      "associated 1\n",
      "penny 1\n",
      "chose 1\n",
      "spits 1\n",
      "eavesdropper 2\n",
      "springs 1\n",
      "flailing 1\n",
      "whole 6\n",
      "sponge 5\n",
      "psychiatrist 5\n",
      "coughs 1\n",
      "offer 1\n",
      "drumming 1\n",
      "heterosexual 1\n",
      "street 14\n",
      "armoire 13\n",
      "yourself 7\n",
      "puzzle 1\n",
      "seats 2\n",
      "kramer 207\n",
      "david 1\n",
      "accompanied 1\n",
      "reads 1\n",
      "quart 1\n",
      "reaction 3\n",
      "cushion 1\n",
      "whatever 4\n",
      "entering 1\n",
      "spend 1\n",
      "leans 1\n",
      "coleslaw 1\n",
      "quietly 1\n",
      "beard 1\n",
      "trips 1\n",
      "crowd 5\n",
      "whack 1\n",
      "rolls 1\n",
      "saying 2\n",
      "preferences 1\n",
      "golden 6\n",
      "spare 1\n",
      "anticipation 1\n",
      "buying 1\n",
      "nearby 1\n",
      "finishing 1\n",
      "insisted 2\n",
      "secretly 1\n",
      "where 28\n",
      "groceries 1\n",
      "wants 5\n",
      "whistling 1\n",
      "biology 1\n",
      "worked 1\n",
      "logic 1\n",
      "spice 1\n",
      "bicker 1\n",
      "blonde 1\n",
      "roommate 1\n",
      "frank 2\n",
      "remove 2\n",
      "military 1\n",
      "regime 1\n",
      "forgets 1\n",
      "tweetie 1\n",
      "implying 1\n",
      "hotel 11\n",
      "reaching 1\n",
      "turns 9\n",
      "stink 1\n",
      "applicant 1\n",
      "forget 2\n",
      "unbearable 1\n",
      "skirt 1\n",
      "aerobics 3\n",
      "under 4\n",
      "swing 1\n",
      "countertop 2\n",
      "pretty 4\n",
      "article 4\n",
      "country 1\n",
      "flash 1\n",
      "toast 4\n",
      "sneakers 3\n",
      "picking 1\n",
      "breakers 1\n",
      "discrimination 1\n",
      "voila 1\n",
      "visiting 2\n",
      "share 2\n",
      "nostrils 1\n",
      "something 28\n",
      "organization 1\n",
      "family 1\n",
      "seconds 1\n",
      "shows 2\n",
      "faces 2\n",
      "silly 1\n",
      "office 6\n",
      "snapping 2\n",
      "definite 1\n",
      "shrugging 1\n",
      "empties 1\n",
      "plankton 1\n",
      "mattingly 1\n",
      "claps 2\n",
      "another 8\n",
      "guarantee 1\n",
      "cucumber 1\n",
      "berserk 1\n",
      "jambalaya 2\n",
      "concentration 1\n",
      "alarm 1\n",
      "virile 1\n",
      "angrily 1\n",
      "beeps 3\n",
      "speaking 2\n",
      "drivers 1\n",
      "chili 1\n",
      "apartment 30\n",
      "modest 1\n",
      "field 2\n",
      "tawny 1\n",
      "interest 2\n",
      "alumni 3\n",
      "looking 10\n",
      "affections 1\n",
      "avenue 1\n",
      "quickly 4\n",
      "madison 1\n",
      "secret 2\n",
      "chagrin 1\n",
      "fishes 1\n",
      "pushes 2\n",
      "recipes 4\n",
      "causing 3\n",
      "convention 1\n",
      "single 4\n",
      "vowing 1\n",
      "thanksgiving 1\n",
      "gulag 1\n",
      "buzzed 2\n",
      "still 18\n",
      "saves 1\n",
      "japansese 2\n",
      "cause 4\n",
      "stories 1\n",
      "steven 1\n",
      "greetings 3\n",
      "myself 8\n",
      "intimidated 1\n",
      "system 1\n",
      "honey 1\n",
      "original 2\n",
      "rushes 1\n",
      "entire 2\n",
      "people 17\n",
      "insulted 1\n",
      "demonstrates 1\n",
      "response 1\n",
      "whether 1\n",
      "shapely 1\n",
      "means 4\n",
      "could 30\n",
      "advance 1\n",
      "teller 1\n",
      "disconnected 1\n",
      "matter 5\n",
      "imagine 2\n",
      "uglier 1\n",
      "bathroom 3\n",
      "shock 1\n",
      "horrible 2\n",
      "returning 1\n",
      "adorable 1\n",
      "laughs 6\n",
      "celebrities 1\n",
      "least 3\n",
      "naked 13\n",
      "barrow 1\n",
      "letterman 1\n",
      "talks 2\n",
      "doing 21\n",
      "squealing 1\n",
      "started 8\n",
      "easier 2\n",
      "midler 1\n",
      "hallway 1\n",
      "allowed 2\n",
      "convincing 1\n",
      "staying 1\n",
      "goodnight 2\n",
      "ramscy 1\n",
      "pressed 1\n",
      "entrez 1\n",
      "button 1\n",
      "party 1\n",
      "teaching 1\n",
      "boyfriend 1\n",
      "obstructing 1\n",
      "workout 2\n",
      "border 1\n",
      "mantle 1\n",
      "super 5\n",
      "louis 1\n",
      "mouth 6\n",
      "toasting 1\n",
      "falling 2\n",
      "minutes 7\n",
      "leads 1\n",
      "visibly 2\n",
      "refer 1\n",
      "police 1\n",
      "taste 2\n",
      "starts 10\n",
      "castanza 1\n",
      "scene 28\n",
      "blown 1\n",
      "buzzer 1\n",
      "appears 1\n",
      "thrown 1\n",
      "weekend 3\n",
      "lunch 6\n",
      "round 6\n",
      "trouble 4\n",
      "actually 8\n",
      "leaving 2\n",
      "travelling 2\n",
      "nodding 5\n",
      "acclaimed 1\n",
      "familiar 2\n",
      "count 2\n",
      "played 1\n",
      "pacino 1\n",
      "salutes 1\n",
      "preparing 1\n",
      "untoasted 1\n",
      "outed 1\n",
      "merger 1\n",
      "cracked 1\n",
      "tribes 1\n",
      "perhaps 2\n",
      "early 1\n",
      "terrible 2\n",
      "fells 1\n",
      "opened 1\n",
      "unhealthy 1\n",
      "amassed 1\n",
      "comments 1\n",
      "earth 1\n",
      "cancelling 1\n",
      "unattractive 1\n",
      "karma 1\n",
      "weird 2\n",
      "interview 2\n",
      "leaves 7\n",
      "bends 1\n",
      "fallen 1\n",
      "forgive 2\n",
      "absorbed 1\n",
      "breathing 2\n",
      "parents 9\n",
      "sweetie 3\n",
      "uncle 1\n",
      "check 2\n",
      "child 1\n",
      "shutting 2\n",
      "mushroom 1\n",
      "floor 4\n",
      "terrorists 1\n",
      "handkerchief 2\n",
      "indonesia 1\n",
      "whales 2\n",
      "first 8\n",
      "danger 1\n",
      "believe 11\n",
      "cards 2\n",
      "robbins 1\n",
      "grievances 1\n",
      "clear 3\n",
      "clutching 1\n",
      "coughing 1\n",
      "couch 6\n",
      "calling 2\n",
      "shook 1\n",
      "changes 1\n",
      "jujyfruit 8\n",
      "angry 1\n",
      "elaine 380\n",
      "completely 3\n",
      "lines 1\n",
      "presence 1\n",
      "sneeze 1\n",
      "realized 2\n",
      "immediately 2\n",
      "publishing 6\n",
      "write 2\n",
      "stand 3\n",
      "moves 2\n",
      "crying 2\n",
      "mentioned 1\n",
      "rejecting 1\n",
      "county 1\n",
      "beyond 1\n",
      "thirties 1\n",
      "person 3\n",
      "secretary 4\n",
      "second 7\n",
      "directly 2\n",
      "because 28\n",
      "understanding 1\n",
      "crashing 1\n",
      "pursuit 1\n",
      "transfixed 1\n",
      "glorification 1\n",
      "commotion 1\n",
      "terrified 1\n",
      "waits 1\n",
      "imitating 1\n",
      "geniuses 1\n",
      "paruba 1\n",
      "without 2\n",
      "chicago 1\n",
      "their 10\n",
      "families 1\n",
      "thousands 1\n",
      "clerk 3\n",
      "decides 2\n",
      "scared 1\n",
      "tobacco 1\n",
      "waving 1\n",
      "conglomerate 1\n",
      "student 1\n",
      "public 2\n",
      "approach 3\n",
      "georgie 2\n",
      "shmoopy 25\n",
      "forehead 3\n",
      "lifestyle 1\n",
      "yello 1\n",
      "circumstances 1\n",
      "nudist 7\n",
      "grows 1\n",
      "virginity 1\n",
      "tomorrow 4\n",
      "rather 3\n",
      "closer 4\n",
      "anyone 4\n",
      "embellish 2\n",
      "books 1\n",
      "pendant 5\n",
      "boing 1\n",
      "diane 22\n",
      "shouting 3\n",
      "chain 1\n",
      "heaven 1\n",
      "fooled 1\n",
      "clunk 1\n",
      "developing 1\n",
      "presents 1\n",
      "olive 2\n",
      "understands 1\n",
      "envelopes 1\n",
      "pockets 1\n",
      "apparently 3\n",
      "evens 1\n",
      "fired 1\n",
      "slamming 2\n",
      "streak 1\n",
      "white 1\n",
      "effect 1\n",
      "procedure 2\n",
      "friend 8\n",
      "affection 1\n",
      "village 1\n",
      "expect 2\n",
      "unlocking 1\n",
      "somewhat 1\n",
      "gotta 19\n",
      "titleist 1\n",
      "bologna 1\n",
      "inhaling 1\n",
      "huuunnnggry 1\n",
      "ooohh 1\n",
      "sneezes 3\n",
      "victoria 12\n",
      "testikov 27\n",
      "medicine 1\n",
      "demand 1\n",
      "focus 1\n",
      "driving 3\n",
      "dropping 2\n",
      "weetie 2\n",
      "mulliga 1\n",
      "walks 9\n",
      "spring 1\n",
      "gehrig 1\n",
      "wishes 1\n",
      "hours 2\n",
      "germs 1\n",
      "squeezes 1\n",
      "besides 1\n",
      "stationary 1\n",
      "relationship 2\n",
      "yellow 1\n",
      "pinkies 1\n",
      "black 1\n",
      "teacher 1\n",
      "hundred 3\n",
      "birthday 5\n",
      "toward 2\n",
      "running 3\n",
      "taken 3\n",
      "geroge 2\n",
      "difference 2\n",
      "cereal 2\n",
      "insult 1\n",
      "anything 22\n",
      "chicken 4\n",
      "hookers 1\n",
      "suddenly 4\n",
      "waaaaugh 1\n",
      "obvious 1\n",
      "leading 1\n",
      "fishy 2\n",
      "nicholson 1\n",
      "asleep 6\n",
      "around 19\n",
      "spotted 1\n",
      "careful 1\n",
      "england 1\n",
      "ridiculous 1\n",
      "clothes 1\n",
      "moved 1\n",
      "affected 1\n",
      "meets 2\n",
      "misunderstood 1\n",
      "kidding 5\n",
      "commenting 1\n",
      "anywhere 2\n",
      "follow 2\n",
      "married 2\n",
      "kicking 1\n",
      "squeaks 1\n",
      "nowhere 1\n",
      "passes 3\n",
      "layaway 1\n",
      "stops 2\n",
      "visit 3\n",
      "camera 2\n",
      "connection 1\n",
      "slipped 1\n",
      "crazy 5\n",
      "receive 1\n",
      "bachelor 1\n",
      "sound 4\n",
      "dressed 4\n",
      "solved 1\n",
      "patch 1\n",
      "shakes 1\n",
      "actor 2\n",
      "shall 1\n",
      "walkin 2\n",
      "glued 1\n",
      "happen 4\n",
      "breaths 1\n",
      "mesmerized 1\n",
      "unusual 1\n",
      "returns 1\n",
      "turned 1\n",
      "quite 12\n",
      "frightening 1\n",
      "previous 2\n",
      "nurse 9\n",
      "evolution 1\n",
      "empty 1\n",
      "getting 10\n",
      "encyclopedia 1\n",
      "golda 1\n",
      "wanting 2\n",
      "babyblue 1\n",
      "divine 1\n",
      "quick 1\n",
      "clearly 1\n",
      "kinship 1\n",
      "ground 1\n"
     ]
    }
   ],
   "source": [
    "#Obtain the frequency of each word\n",
    "match_pattern = re.findall(r'\\b[a-z]{5,15}\\b', text)\n",
    "frequency = {}\n",
    "\n",
    "for word in match_pattern:\n",
    "    count = frequency.get(word,0)\n",
    "    frequency[word] = count + 1\n",
    "\n",
    "frequency_list = frequency.keys()\n",
    "\n",
    "for words in frequency_list:\n",
    "    print(words, frequency[words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of tuples containing the word and the frequency of the word\n",
    "results = []\n",
    "for word in frequency_list:\n",
    "    tuple = (word, frequency[word])\n",
    "    results.append(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the list\n",
    "byFreq=sorted(results, key=lambda word: word[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jerry', 581),\n",
       " ('george', 414),\n",
       " ('elaine', 380),\n",
       " ('kramer', 207),\n",
       " ('there', 89),\n",
       " ('right', 65),\n",
       " ('about', 55),\n",
       " ('think', 47),\n",
       " ('gonna', 46),\n",
       " ('going', 42)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top ten most frequent words\n",
    "byFreq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jerry 581\n",
      "george 414\n",
      "elaine 380\n",
      "kramer 207\n",
      "there 89\n",
      "right 65\n",
      "about 55\n",
      "think 47\n",
      "gonna 46\n",
      "going 42\n"
     ]
    }
   ],
   "source": [
    "#Seperate tuples into seperate lists\n",
    "words_names=[]\n",
    "words_count=[]\n",
    "for (word, freq) in byFreq[:10]:\n",
    "    print (word, freq)\n",
    "    words_names.append(word)\n",
    "    words_count.append(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram using matplotlib bar()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xlabel('Top 10 Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Plotting Word Frequency')\n",
    "indexes = np.arange(len(words_names) )\n",
    "width = .4\n",
    "plt.bar(indexes, words_count, width)\n",
    "plt.xticks(indexes + width * .4, words_names)\n",
    "#plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using nltk tokenize text\n",
    "tokens = nltk.word_tokenize(text)\n",
    "mytext = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot dispersion plot showing when and how often names are mentioned\n",
    "plt.figure(figsize=(15,5))\n",
    "mytext.dispersion_plot([\"jerry\", \"george\", \"elaine\", \"kramer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing LSTM Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map characters to numbers\n",
    "characters = sorted(list(set(text)))\n",
    "\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and target arrays\n",
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape and scale X. Use one hot encoding for y\n",
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create simple neural network\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "109310/109310 [==============================] - 1816s 17ms/step - loss: 2.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2189218a7b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train simple model\n",
    "model.fit(X_modified, Y_modified, epochs=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create prediction text\n",
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"h)\\njerry: (to elaine) let me ask you a question.\\nelaine: mm-hm.\\njerry: you're a hostage, captured bye the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the th\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print prediction text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and target arrays\n",
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape and scale X. Use One hot encoding for Y\n",
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Early Stopping Monitor\n",
    "early_stopping_monitor = EarlyStopping(patience = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 2.1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\callbacks.py:535: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 2.0936\n",
      "Epoch 3/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 2.0795\n",
      "Epoch 4/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 2.0678\n",
      "Epoch 5/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 2.0564\n",
      "Epoch 6/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 2.0464\n",
      "Epoch 7/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 2.0365\n",
      "Epoch 8/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 2.0243\n",
      "Epoch 9/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 2.0146\n",
      "Epoch 10/50\n",
      "109310/109310 [==============================] - 821s 8ms/step - loss: 2.0097\n",
      "Epoch 11/50\n",
      "109310/109310 [==============================] - 821s 8ms/step - loss: 1.9978\n",
      "Epoch 12/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 1.9889\n",
      "Epoch 13/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9840\n",
      "Epoch 14/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9788\n",
      "Epoch 15/50\n",
      "109310/109310 [==============================] - 821s 8ms/step - loss: 1.9688\n",
      "Epoch 16/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9628\n",
      "Epoch 17/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9564\n",
      "Epoch 18/50\n",
      "109310/109310 [==============================] - 821s 8ms/step - loss: 1.9482\n",
      "Epoch 19/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9397\n",
      "Epoch 20/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9363\n",
      "Epoch 21/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.9309\n",
      "Epoch 22/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9291\n",
      "Epoch 23/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.9219\n",
      "Epoch 24/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 1.9166\n",
      "Epoch 25/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.9103\n",
      "Epoch 26/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9060\n",
      "Epoch 27/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9029\n",
      "Epoch 28/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.8978\n",
      "Epoch 29/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 1.8936\n",
      "Epoch 30/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.8915\n",
      "Epoch 31/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.8834\n",
      "Epoch 32/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.8814\n",
      "Epoch 33/50\n",
      "109310/109310 [==============================] - 821s 8ms/step - loss: 1.8758\n",
      "Epoch 34/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.8753\n",
      "Epoch 35/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.8709\n",
      "Epoch 36/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 1.8675\n",
      "Epoch 37/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.8634\n",
      "Epoch 38/50\n",
      "109310/109310 [==============================] - 826s 8ms/step - loss: 1.8584\n",
      "Epoch 39/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.8602\n",
      "Epoch 40/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.8527\n",
      "Epoch 41/50\n",
      "109310/109310 [==============================] - 832s 8ms/step - loss: 1.8536\n",
      "Epoch 42/50\n",
      "109310/109310 [==============================] - 833s 8ms/step - loss: 1.8477\n",
      "Epoch 43/50\n",
      "109310/109310 [==============================] - 828s 8ms/step - loss: 1.8459\n",
      "Epoch 44/50\n",
      "109310/109310 [==============================] - 830s 8ms/step - loss: 1.8421\n",
      "Epoch 45/50\n",
      "109310/109310 [==============================] - 830s 8ms/step - loss: 1.8408\n",
      "Epoch 46/50\n",
      "109310/109310 [==============================] - 878s 8ms/step - loss: 1.8361\n",
      "Epoch 47/50\n",
      "109310/109310 [==============================] - 848s 8ms/step - loss: 1.8363\n",
      "Epoch 48/50\n",
      "109310/109310 [==============================] - 864s 8ms/step - loss: 1.8305\n",
      "Epoch 49/50\n",
      "109310/109310 [==============================] - 874s 8ms/step - loss: 1.8286\n",
      "Epoch 50/50\n",
      "109310/109310 [==============================] - 963s 9ms/step - loss: 1.8293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b1a71db38>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using 50 epochs\n",
    "model.fit(X_modified, Y_modified, epochs=50, batch_size=50, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create prediction text\n",
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"h)\\njerry: (to elaine) let me ask you a question.\\nelaine: mm-hm.\\njerry: you're a hostage, captured by the tame out of the sale gor the shonod the was and the sale tie tame eisersiie are to the shooow of the sale eoon the couertion of the sale eoon the couer of the sale eoon the couertion of the sale eoon the couertion.\\n \\n \\ngeorge: yeah. weah, i don't know what i say io the was of the sale wanking to the shinks of the same good and the sale eoon the couertion of the street. i got the shnnop of the\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create prediction text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created training and target arrays\n",
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape and Scale X. Use One Hot Encoding on Y\n",
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create neural network with more 200 nodes\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "109310/109310 [==============================] - 1021s 9ms/step - loss: 2.9218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\callbacks.py:535: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "109310/109310 [==============================] - 1022s 9ms/step - loss: 2.5981\n",
      "Epoch 3/100\n",
      "109310/109310 [==============================] - 1026s 9ms/step - loss: 2.4583\n",
      "Epoch 4/100\n",
      "109310/109310 [==============================] - 1030s 9ms/step - loss: 2.3498\n",
      "Epoch 5/100\n",
      "109310/109310 [==============================] - 1032s 9ms/step - loss: 2.2630\n",
      "Epoch 6/100\n",
      "109310/109310 [==============================] - 1036s 9ms/step - loss: 2.1887\n",
      "Epoch 7/100\n",
      "109310/109310 [==============================] - 1039s 10ms/step - loss: 2.1270\n",
      "Epoch 8/100\n",
      "109310/109310 [==============================] - 1039s 10ms/step - loss: 2.0720\n",
      "Epoch 9/100\n",
      "109310/109310 [==============================] - 1042s 10ms/step - loss: 2.0283\n",
      "Epoch 10/100\n",
      "109310/109310 [==============================] - 1061s 10ms/step - loss: 1.9880\n",
      "Epoch 11/100\n",
      "109310/109310 [==============================] - 1056s 10ms/step - loss: 1.9476\n",
      "Epoch 12/100\n",
      "109310/109310 [==============================] - 1054s 10ms/step - loss: 1.9187\n",
      "Epoch 13/100\n",
      "109310/109310 [==============================] - 1055s 10ms/step - loss: 1.8911\n",
      "Epoch 14/100\n",
      "109310/109310 [==============================] - 1058s 10ms/step - loss: 1.8615\n",
      "Epoch 15/100\n",
      "109310/109310 [==============================] - 1057s 10ms/step - loss: 1.8321\n",
      "Epoch 16/100\n",
      "109310/109310 [==============================] - 1058s 10ms/step - loss: 1.8048\n",
      "Epoch 17/100\n",
      "109310/109310 [==============================] - 1061s 10ms/step - loss: 1.7848\n",
      "Epoch 18/100\n",
      "109310/109310 [==============================] - 1063s 10ms/step - loss: 1.7653\n",
      "Epoch 19/100\n",
      "109310/109310 [==============================] - 1062s 10ms/step - loss: 1.7426\n",
      "Epoch 20/100\n",
      "109310/109310 [==============================] - 1059s 10ms/step - loss: 1.7233\n",
      "Epoch 21/100\n",
      "109310/109310 [==============================] - 1059s 10ms/step - loss: 1.7078\n",
      "Epoch 22/100\n",
      "109310/109310 [==============================] - 1059s 10ms/step - loss: 1.6935\n",
      "Epoch 23/100\n",
      "109310/109310 [==============================] - 1065s 10ms/step - loss: 1.6737\n",
      "Epoch 24/100\n",
      "109310/109310 [==============================] - 1061s 10ms/step - loss: 1.6616\n",
      "Epoch 25/100\n",
      "109310/109310 [==============================] - 1051s 10ms/step - loss: 1.6444\n",
      "Epoch 26/100\n",
      "109310/109310 [==============================] - 2648s 24ms/step - loss: 1.6324\n",
      "Epoch 27/100\n",
      "109310/109310 [==============================] - 2341s 21ms/step - loss: 1.6185\n",
      "Epoch 28/100\n",
      "109310/109310 [==============================] - 1053s 10ms/step - loss: 1.6070\n",
      "Epoch 29/100\n",
      "109310/109310 [==============================] - 1044s 10ms/step - loss: 1.5965\n",
      "Epoch 30/100\n",
      "109310/109310 [==============================] - 1041s 10ms/step - loss: 1.5835\n",
      "Epoch 31/100\n",
      "109310/109310 [==============================] - 1038s 9ms/step - loss: 1.5773\n",
      "Epoch 32/100\n",
      "109310/109310 [==============================] - 1034s 9ms/step - loss: 1.5661\n",
      "Epoch 33/100\n",
      "109310/109310 [==============================] - 1038s 9ms/step - loss: 1.5565\n",
      "Epoch 34/100\n",
      "109310/109310 [==============================] - 1031s 9ms/step - loss: 1.5441\n",
      "Epoch 35/100\n",
      "109310/109310 [==============================] - 1031s 9ms/step - loss: 1.5365\n",
      "Epoch 36/100\n",
      "109310/109310 [==============================] - 1029s 9ms/step - loss: 1.5298\n",
      "Epoch 37/100\n",
      "109310/109310 [==============================] - 1030s 9ms/step - loss: 1.5218\n",
      "Epoch 38/100\n",
      "109310/109310 [==============================] - 1028s 9ms/step - loss: 1.5135\n",
      "Epoch 39/100\n",
      "109310/109310 [==============================] - 1030s 9ms/step - loss: 1.5083\n",
      "Epoch 40/100\n",
      "109310/109310 [==============================] - 1026s 9ms/step - loss: 1.4999\n",
      "Epoch 41/100\n",
      "109310/109310 [==============================] - 1026s 9ms/step - loss: 1.4947\n",
      "Epoch 42/100\n",
      "109310/109310 [==============================] - 1026s 9ms/step - loss: 1.4861\n",
      "Epoch 43/100\n",
      "109310/109310 [==============================] - 1024s 9ms/step - loss: 1.4823\n",
      "Epoch 44/100\n",
      "109310/109310 [==============================] - 1023s 9ms/step - loss: 1.4761\n",
      "Epoch 45/100\n",
      "109310/109310 [==============================] - 1023s 9ms/step - loss: 1.4656\n",
      "Epoch 46/100\n",
      "109310/109310 [==============================] - 1020s 9ms/step - loss: 1.4611\n",
      "Epoch 47/100\n",
      "109310/109310 [==============================] - 1018s 9ms/step - loss: 1.4565\n",
      "Epoch 48/100\n",
      "109310/109310 [==============================] - 1031s 9ms/step - loss: 1.4523\n",
      "Epoch 49/100\n",
      "109310/109310 [==============================] - 1022s 9ms/step - loss: 1.4504\n",
      "Epoch 50/100\n",
      "109310/109310 [==============================] - 1023s 9ms/step - loss: 1.4428\n",
      "Epoch 51/100\n",
      "109310/109310 [==============================] - 1019s 9ms/step - loss: 1.4373\n",
      "Epoch 52/100\n",
      "109310/109310 [==============================] - 1019s 9ms/step - loss: 1.4336\n",
      "Epoch 53/100\n",
      "109310/109310 [==============================] - 1020s 9ms/step - loss: 1.4301\n",
      "Epoch 54/100\n",
      "109310/109310 [==============================] - 1016s 9ms/step - loss: 1.4229\n",
      "Epoch 55/100\n",
      "109310/109310 [==============================] - 1016s 9ms/step - loss: 1.4183\n",
      "Epoch 56/100\n",
      "109310/109310 [==============================] - 1019s 9ms/step - loss: 1.4142\n",
      "Epoch 57/100\n",
      "109310/109310 [==============================] - 1023s 9ms/step - loss: 1.4126\n",
      "Epoch 58/100\n",
      "109310/109310 [==============================] - 1018s 9ms/step - loss: 1.4046\n",
      "Epoch 59/100\n",
      "109310/109310 [==============================] - 1019s 9ms/step - loss: 1.4076\n",
      "Epoch 60/100\n",
      "109310/109310 [==============================] - 1022s 9ms/step - loss: 1.3993\n",
      "Epoch 61/100\n",
      "109310/109310 [==============================] - 1020s 9ms/step - loss: 1.3963\n",
      "Epoch 62/100\n",
      "109310/109310 [==============================] - 1021s 9ms/step - loss: 1.3921\n",
      "Epoch 63/100\n",
      "109310/109310 [==============================] - 1022s 9ms/step - loss: 1.3890\n",
      "Epoch 64/100\n",
      "109310/109310 [==============================] - 1023s 9ms/step - loss: 1.3848\n",
      "Epoch 65/100\n",
      "109310/109310 [==============================] - 1022s 9ms/step - loss: 1.3836\n",
      "Epoch 66/100\n",
      "109310/109310 [==============================] - 1029s 9ms/step - loss: 1.3762\n",
      "Epoch 67/100\n",
      "109310/109310 [==============================] - 1030s 9ms/step - loss: 1.3757\n",
      "Epoch 68/100\n",
      "109310/109310 [==============================] - 1027s 9ms/step - loss: 1.3734\n",
      "Epoch 69/100\n",
      "109310/109310 [==============================] - 1026s 9ms/step - loss: 1.3668\n",
      "Epoch 70/100\n",
      "109310/109310 [==============================] - 1030s 9ms/step - loss: 1.3678\n",
      "Epoch 71/100\n",
      "109310/109310 [==============================] - 1029s 9ms/step - loss: 1.3701\n",
      "Epoch 72/100\n",
      "109310/109310 [==============================] - 1031s 9ms/step - loss: 2.4674\n",
      "Epoch 73/100\n",
      "109310/109310 [==============================] - 1031s 9ms/step - loss: 1.5773\n",
      "Epoch 74/100\n",
      "109310/109310 [==============================] - 1034s 9ms/step - loss: 1.4078\n",
      "Epoch 75/100\n",
      "109310/109310 [==============================] - 1032s 9ms/step - loss: 1.3475\n",
      "Epoch 76/100\n",
      "109310/109310 [==============================] - 1035s 9ms/step - loss: 1.3307\n",
      "Epoch 77/100\n",
      "109310/109310 [==============================] - 1038s 9ms/step - loss: 1.3327\n",
      "Epoch 78/100\n",
      "109310/109310 [==============================] - 1040s 10ms/step - loss: 1.3484\n",
      "Epoch 79/100\n",
      "109310/109310 [==============================] - 1043s 10ms/step - loss: 1.3536\n",
      "Epoch 80/100\n",
      "109310/109310 [==============================] - 1043s 10ms/step - loss: 1.3619\n",
      "Epoch 81/100\n",
      "109310/109310 [==============================] - 1045s 10ms/step - loss: 1.3631\n",
      "Epoch 82/100\n",
      "109310/109310 [==============================] - 1047s 10ms/step - loss: 1.3562\n",
      "Epoch 83/100\n",
      "109310/109310 [==============================] - 1047s 10ms/step - loss: 1.3527\n",
      "Epoch 84/100\n",
      "109310/109310 [==============================] - 1048s 10ms/step - loss: 1.3513\n",
      "Epoch 85/100\n",
      "109310/109310 [==============================] - 1047s 10ms/step - loss: 1.3479\n",
      "Epoch 86/100\n",
      "109310/109310 [==============================] - 1048s 10ms/step - loss: 1.3457\n",
      "Epoch 87/100\n",
      "109310/109310 [==============================] - 1051s 10ms/step - loss: 1.3440\n",
      "Epoch 88/100\n",
      "109310/109310 [==============================] - 1053s 10ms/step - loss: 1.3405\n",
      "Epoch 89/100\n",
      "109310/109310 [==============================] - 1052s 10ms/step - loss: 1.3331\n",
      "Epoch 90/100\n",
      "109310/109310 [==============================] - 1038s 9ms/step - loss: 1.3360\n",
      "Epoch 91/100\n",
      "109310/109310 [==============================] - 1042s 10ms/step - loss: 1.3415\n",
      "Epoch 92/100\n",
      "109310/109310 [==============================] - 1042s 10ms/step - loss: 1.3323\n",
      "Epoch 93/100\n",
      "109310/109310 [==============================] - 1053s 10ms/step - loss: 1.3267\n",
      "Epoch 94/100\n",
      "109310/109310 [==============================] - 1055s 10ms/step - loss: 1.3310\n",
      "Epoch 95/100\n",
      "109310/109310 [==============================] - 1051s 10ms/step - loss: 1.3212\n",
      "Epoch 96/100\n",
      "109310/109310 [==============================] - 1048s 10ms/step - loss: 1.3287\n",
      "Epoch 97/100\n",
      "109310/109310 [==============================] - 1047s 10ms/step - loss: 1.3208\n",
      "Epoch 98/100\n",
      "109310/109310 [==============================] - 1046s 10ms/step - loss: 1.3137\n",
      "Epoch 99/100\n",
      "109310/109310 [==============================] - 1044s 10ms/step - loss: 1.3177\n",
      "Epoch 100/100\n",
      "109310/109310 [==============================] - 1042s 10ms/step - loss: 1.3168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20cace2e320>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train model with 100 epochs\n",
    "model.fit(X_modified, Y_modified, epochs=100, batch_size=50, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create prediction text\n",
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"h)\\njerry: (to elaine) let me ask you a question.\\nelaine: mm-hm.\\njerry: you're a hostage, captured by the opposite of my lame in the cid he and george an oyt leatery passer and she says the sacle tp the thonopad works on the hoop wour sime shat wour hard sere for a call ort to mnee at the mopo of the can and she samking about the sope fach oige the wash in the coffee thop the shonop.\\ngeorge: i don't know wou do the samd bout on the street.\\nelaine: what about the soup nazi.\\n \\nelaine: yeah. i know \""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print prediction text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and target arrays\n",
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape and transform X. Use one hot encoding for Y\n",
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create neural network with 400 nodes\n",
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "109310/109310 [==============================] - 3791s 35ms/step - loss: 2.8195\n",
      "Epoch 2/100\n",
      "109310/109310 [==============================] - 3837s 35ms/step - loss: 2.3771\n",
      "Epoch 3/100\n",
      "109310/109310 [==============================] - 3842s 35ms/step - loss: 2.1506\n",
      "Epoch 4/100\n",
      "109310/109310 [==============================] - 3842s 35ms/step - loss: 1.9898\n",
      "Epoch 5/100\n",
      "109310/109310 [==============================] - 3842s 35ms/step - loss: 1.8684\n",
      "Epoch 6/100\n",
      "109310/109310 [==============================] - 3844s 35ms/step - loss: 1.7698\n",
      "Epoch 7/100\n",
      "109310/109310 [==============================] - 3843s 35ms/step - loss: 1.6802\n",
      "Epoch 8/100\n",
      "109310/109310 [==============================] - 3845s 35ms/step - loss: 1.6006\n",
      "Epoch 9/100\n",
      "109310/109310 [==============================] - 3847s 35ms/step - loss: 1.5281\n",
      "Epoch 10/100\n",
      "109310/109310 [==============================] - 3846s 35ms/step - loss: 1.4636\n",
      "Epoch 11/100\n",
      "109310/109310 [==============================] - 3844s 35ms/step - loss: 1.3947\n",
      "Epoch 12/100\n",
      "109310/109310 [==============================] - 3843s 35ms/step - loss: 1.3381\n",
      "Epoch 13/100\n",
      "109310/109310 [==============================] - 3844s 35ms/step - loss: 1.2805\n",
      "Epoch 14/100\n",
      "109310/109310 [==============================] - 3845s 35ms/step - loss: 1.2325\n",
      "Epoch 15/100\n",
      "109310/109310 [==============================] - 3845s 35ms/step - loss: 1.1857\n",
      "Epoch 16/100\n",
      "109310/109310 [==============================] - 3844s 35ms/step - loss: 1.1424\n",
      "Epoch 17/100\n",
      "109310/109310 [==============================] - 3844s 35ms/step - loss: 1.1009\n",
      "Epoch 18/100\n",
      "109310/109310 [==============================] - 3869s 35ms/step - loss: 1.0609\n",
      "Epoch 19/100\n",
      "109310/109310 [==============================] - 4008s 37ms/step - loss: 1.0284\n",
      "Epoch 20/100\n",
      "109310/109310 [==============================] - 3976s 36ms/step - loss: 1.0020\n",
      "Epoch 21/100\n",
      "109310/109310 [==============================] - 4129s 38ms/step - loss: 0.9708\n",
      "Epoch 22/100\n",
      "109310/109310 [==============================] - 4012s 37ms/step - loss: 0.9505\n",
      "Epoch 23/100\n",
      "109310/109310 [==============================] - 3915s 36ms/step - loss: 0.9247\n",
      "Epoch 24/100\n",
      "109310/109310 [==============================] - 3911s 36ms/step - loss: 0.9030\n",
      "Epoch 25/100\n",
      "109310/109310 [==============================] - 3913s 36ms/step - loss: 0.8840\n",
      "Epoch 26/100\n",
      "109310/109310 [==============================] - 3909s 36ms/step - loss: 0.8682\n",
      "Epoch 27/100\n",
      "109310/109310 [==============================] - 3913s 36ms/step - loss: 0.8530\n",
      "Epoch 28/100\n",
      "109310/109310 [==============================] - 3912s 36ms/step - loss: 0.8383\n",
      "Epoch 29/100\n",
      "109310/109310 [==============================] - 3912s 36ms/step - loss: 0.8267\n",
      "Epoch 30/100\n",
      "109310/109310 [==============================] - 3914s 36ms/step - loss: 0.8090\n",
      "Epoch 31/100\n",
      "109310/109310 [==============================] - 3913s 36ms/step - loss: 0.8047\n",
      "Epoch 32/100\n",
      "109310/109310 [==============================] - 3912s 36ms/step - loss: 0.7895\n",
      "Epoch 33/100\n",
      "109310/109310 [==============================] - 3913s 36ms/step - loss: 0.7799\n",
      "Epoch 34/100\n",
      "109310/109310 [==============================] - 3913s 36ms/step - loss: 0.7735\n",
      "Epoch 35/100\n",
      "109310/109310 [==============================] - 3915s 36ms/step - loss: 0.7636\n",
      "Epoch 36/100\n",
      "109310/109310 [==============================] - 3912s 36ms/step - loss: 0.7562\n",
      "Epoch 37/100\n",
      "109310/109310 [==============================] - 3913s 36ms/step - loss: 0.7505\n",
      "Epoch 38/100\n",
      "109310/109310 [==============================] - 3912s 36ms/step - loss: 0.7435\n",
      "Epoch 39/100\n",
      "109310/109310 [==============================] - 3913s 36ms/step - loss: 0.7360\n",
      "Epoch 40/100\n",
      "109310/109310 [==============================] - 3942s 36ms/step - loss: 0.7309\n",
      "Epoch 41/100\n",
      "109310/109310 [==============================] - 3979s 36ms/step - loss: 0.7232\n",
      "Epoch 42/100\n",
      "109310/109310 [==============================] - 3925s 36ms/step - loss: 0.7177\n",
      "Epoch 43/100\n",
      "109310/109310 [==============================] - 3989s 36ms/step - loss: 0.7231\n",
      "Epoch 44/100\n",
      "109310/109310 [==============================] - 3900s 36ms/step - loss: 0.7125\n",
      "Epoch 45/100\n",
      "109310/109310 [==============================] - 3915s 36ms/step - loss: 0.7075\n",
      "Epoch 46/100\n",
      "109310/109310 [==============================] - 3917s 36ms/step - loss: 0.7047\n",
      "Epoch 47/100\n",
      "109310/109310 [==============================] - 3914s 36ms/step - loss: 0.6959\n",
      "Epoch 48/100\n",
      "109310/109310 [==============================] - 3915s 36ms/step - loss: 0.6940\n",
      "Epoch 49/100\n",
      "109310/109310 [==============================] - 3916s 36ms/step - loss: 0.6906\n",
      "Epoch 50/100\n",
      "109310/109310 [==============================] - 3915s 36ms/step - loss: 0.6887\n",
      "Epoch 51/100\n",
      "109310/109310 [==============================] - 3917s 36ms/step - loss: 0.6827\n",
      "Epoch 52/100\n",
      "109310/109310 [==============================] - 3916s 36ms/step - loss: 0.6779\n",
      "Epoch 53/100\n",
      "109310/109310 [==============================] - 3918s 36ms/step - loss: 0.6737\n",
      "Epoch 54/100\n",
      "109310/109310 [==============================] - 3914s 36ms/step - loss: 0.6696\n",
      "Epoch 55/100\n",
      "109310/109310 [==============================] - 3912s 36ms/step - loss: 0.6654\n",
      "Epoch 56/100\n",
      "109310/109310 [==============================] - 3914s 36ms/step - loss: 0.6730\n",
      "Epoch 57/100\n",
      "109310/109310 [==============================] - 3912s 36ms/step - loss: 0.6686\n",
      "Epoch 58/100\n",
      "109310/109310 [==============================] - 3911s 36ms/step - loss: 0.6686\n",
      "Epoch 59/100\n",
      "109310/109310 [==============================] - 3912s 36ms/step - loss: 0.6560\n",
      "Epoch 60/100\n",
      "109310/109310 [==============================] - 3911s 36ms/step - loss: 0.6557\n",
      "Epoch 61/100\n",
      "109310/109310 [==============================] - 3914s 36ms/step - loss: 0.6665\n",
      "Epoch 62/100\n",
      "109310/109310 [==============================] - 3910s 36ms/step - loss: 0.6658\n",
      "Epoch 63/100\n",
      "109310/109310 [==============================] - 3995s 37ms/step - loss: 0.6616\n",
      "Epoch 64/100\n",
      "109310/109310 [==============================] - 3916s 36ms/step - loss: 0.6550\n",
      "Epoch 65/100\n",
      "109310/109310 [==============================] - 3978s 36ms/step - loss: 0.6556\n",
      "Epoch 66/100\n",
      "109310/109310 [==============================] - 3898s 36ms/step - loss: 0.6571\n",
      "Epoch 67/100\n",
      "109310/109310 [==============================] - 3897s 36ms/step - loss: 0.6582\n",
      "Epoch 68/100\n",
      "109310/109310 [==============================] - 3895s 36ms/step - loss: 0.6479\n",
      "Epoch 69/100\n",
      "109310/109310 [==============================] - 3899s 36ms/step - loss: 0.6436\n",
      "Epoch 70/100\n",
      "109310/109310 [==============================] - 3899s 36ms/step - loss: 0.6463\n",
      "Epoch 71/100\n",
      "109310/109310 [==============================] - 3899s 36ms/step - loss: 0.6437\n",
      "Epoch 72/100\n",
      "109310/109310 [==============================] - 3898s 36ms/step - loss: 0.6569\n",
      "Epoch 73/100\n",
      "109310/109310 [==============================] - 3901s 36ms/step - loss: 0.6489\n",
      "Epoch 74/100\n",
      "109310/109310 [==============================] - 3898s 36ms/step - loss: 0.6451\n",
      "Epoch 75/100\n",
      "109310/109310 [==============================] - 3916s 36ms/step - loss: 0.6414\n",
      "Epoch 76/100\n",
      "109310/109310 [==============================] - 3916s 36ms/step - loss: 0.6421\n",
      "Epoch 77/100\n",
      "109310/109310 [==============================] - 3914s 36ms/step - loss: 0.6415\n",
      "Epoch 78/100\n",
      "109310/109310 [==============================] - 3915s 36ms/step - loss: 0.6414\n",
      "Epoch 79/100\n",
      "109310/109310 [==============================] - 3917s 36ms/step - loss: 0.6355\n",
      "Epoch 80/100\n",
      "109310/109310 [==============================] - 3916s 36ms/step - loss: 0.6343\n",
      "Epoch 81/100\n",
      "109310/109310 [==============================] - 3916s 36ms/step - loss: 0.6294\n",
      "Epoch 82/100\n",
      "109310/109310 [==============================] - 3914s 36ms/step - loss: 0.6403\n",
      "Epoch 83/100\n",
      "109310/109310 [==============================] - 3916s 36ms/step - loss: 0.6355\n",
      "Epoch 84/100\n",
      "109310/109310 [==============================] - 3917s 36ms/step - loss: 0.6353\n",
      "Epoch 85/100\n",
      "109310/109310 [==============================] - 3914s 36ms/step - loss: 0.6390\n",
      "Epoch 86/100\n",
      "109310/109310 [==============================] - 3917s 36ms/step - loss: 0.6319\n",
      "Epoch 87/100\n",
      "109310/109310 [==============================] - 3917s 36ms/step - loss: 0.6345\n",
      "Epoch 88/100\n",
      "109310/109310 [==============================] - 3917s 36ms/step - loss: 0.6367\n",
      "Epoch 89/100\n",
      "109310/109310 [==============================] - 3906s 36ms/step - loss: 0.6361\n",
      "Epoch 90/100\n",
      "109310/109310 [==============================] - 3906s 36ms/step - loss: 0.6348\n",
      "Epoch 91/100\n",
      "109310/109310 [==============================] - 3903s 36ms/step - loss: 0.6308\n",
      "Epoch 92/100\n",
      "109310/109310 [==============================] - 3907s 36ms/step - loss: 0.6339\n",
      "Epoch 93/100\n",
      "109310/109310 [==============================] - 3906s 36ms/step - loss: 0.6365\n",
      "Epoch 94/100\n",
      "109310/109310 [==============================] - 3910s 36ms/step - loss: 0.6370\n",
      "Epoch 95/100\n",
      "109310/109310 [==============================] - 3904s 36ms/step - loss: 0.6264\n",
      "Epoch 96/100\n",
      "109310/109310 [==============================] - 3908s 36ms/step - loss: 0.6241\n",
      "Epoch 97/100\n",
      "109310/109310 [==============================] - 3907s 36ms/step - loss: 0.6297\n",
      "Epoch 98/100\n",
      "109310/109310 [==============================] - 3909s 36ms/step - loss: 0.6332\n",
      "Epoch 99/100\n",
      "109310/109310 [==============================] - 3908s 36ms/step - loss: 0.6349\n",
      "Epoch 100/100\n",
      "109310/109310 [==============================] - 3906s 36ms/step - loss: 0.6364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1caf4acf978>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train model over 100 epochs\n",
    "model.fit(X_modified, Y_modified, epochs=100, batch_size=50)http://localhost:8888/notebooks/Capstone_Project2.ipynb#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create prediction text\n",
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"h)\\njerry: (to elaine) let me ask you a question.\\nelaine: mm-hm.\\njerry: you're a hostage, captured by terrorists-\\nelaine: (smiling, choekding) nh. it's ouerty good. huh?\\n \\njerry: well, well.  \\nsusan: himho. you're there and they don't have to say for yourself.\\nelaine: oh, it was nike for me to be around no tomething.\\njerry: (pointing) yeah. i'm aoming. i'm vellin' he didn't shake it up in the meeting?\\n \\n(jerry picks up the money, cousinuation to the bouiter) she's sleeping with his mother)\\ngeorge\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print prediction text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and target arrays\n",
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape and transform X. Use one hot encoding for Y\n",
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create neural network with 700 nodes\n",
    "model = Sequential()\n",
    "model.add(LSTM(700, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(700, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(700))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "109310/109310 [==============================] - 8828s 81ms/step - loss: 3.0416\n",
      "Epoch 2/25\n",
      "109310/109310 [==============================] - 8833s 81ms/step - loss: 2.5672\n",
      "Epoch 3/25\n",
      "109310/109310 [==============================] - 8840s 81ms/step - loss: 2.3003\n",
      "Epoch 4/25\n",
      "109310/109310 [==============================] - 8838s 81ms/step - loss: 2.1233\n",
      "Epoch 5/25\n",
      "109310/109310 [==============================] - 8834s 81ms/step - loss: 1.9921\n",
      "Epoch 6/25\n",
      "109310/109310 [==============================] - 8835s 81ms/step - loss: 1.8863\n",
      "Epoch 7/25\n",
      "109310/109310 [==============================] - 8832s 81ms/step - loss: 1.8013\n",
      "Epoch 8/25\n",
      "109310/109310 [==============================] - 8840s 81ms/step - loss: 1.7260\n",
      "Epoch 9/25\n",
      "109310/109310 [==============================] - 8946s 82ms/step - loss: 1.6612\n",
      "Epoch 10/25\n",
      "109310/109310 [==============================] - 9227s 84ms/step - loss: 1.5971\n",
      "Epoch 11/25\n",
      "109310/109310 [==============================] - 9224s 84ms/step - loss: 1.5420\n",
      "Epoch 12/25\n",
      "109310/109310 [==============================] - 9228s 84ms/step - loss: 1.4901\n",
      "Epoch 13/25\n",
      "109310/109310 [==============================] - 9225s 84ms/step - loss: 1.4357\n",
      "Epoch 14/25\n",
      "109310/109310 [==============================] - 9221s 84ms/step - loss: 1.3879\n",
      "Epoch 15/25\n",
      "109310/109310 [==============================] - 9231s 84ms/step - loss: 1.3468\n",
      "Epoch 16/25\n",
      "109310/109310 [==============================] - 9225s 84ms/step - loss: 1.3086\n",
      "Epoch 17/25\n",
      "109310/109310 [==============================] - 9228s 84ms/step - loss: 1.2690\n",
      "Epoch 18/25\n",
      "109310/109310 [==============================] - 9227s 84ms/step - loss: 1.2319\n",
      "Epoch 19/25\n",
      "109310/109310 [==============================] - 9228s 84ms/step - loss: 1.2004\n",
      "Epoch 20/25\n",
      "109310/109310 [==============================] - 9240s 85ms/step - loss: 1.1595\n",
      "Epoch 21/25\n",
      "109310/109310 [==============================] - 9229s 84ms/step - loss: 1.1311\n",
      "Epoch 22/25\n",
      "109310/109310 [==============================] - 9230s 84ms/step - loss: 1.1012\n",
      "Epoch 23/25\n",
      "109310/109310 [==============================] - 9222s 84ms/step - loss: 1.0783\n",
      "Epoch 24/25\n",
      "109310/109310 [==============================] - 9229s 84ms/step - loss: 1.0474\n",
      "Epoch 25/25\n",
      "109310/109310 [==============================] - 9233s 84ms/step - loss: 1.0282\n"
     ]
    }
   ],
   "source": [
    "#Train model with 25 epochs\n",
    "model.fit(X_modified, Y_modified, epochs=25, batch_size=50)\n",
    "\n",
    "model.save_weights('model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create prediction text\n",
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h)\\njerry: (to elaine) let me ask you a question.\\nelaine: mm-hm.\\njerry: you\\'re a hostage, captured by toup.\\n \\njerry: well, i got two bame of the convestation. ie saids the table and the says the seaction hall the window and that heorge says \" the shme with the ohone.\\nelaine: what?\\ngeorge: yeah, ie didn\\'t have the truth!(he says the seseemt is up and ie says to her and the says to het to het to het to and they could hiv toup in the coffee thop.\\n \\njerry: what is that iappened?\\njerry: i don\\'t know. '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print prediction text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
