{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Necessary Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load text file\n",
    "text = (open(\"Seinfeld_Scripts.txt\").read())\n",
    "text=text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "109310/109310 [==============================] - 1816s 17ms/step - loss: 2.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2189218a7b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=1, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"h)\\njerry: (to elaine) let me ask you a question.\\nelaine: mm-hm.\\njerry: you're a hostage, captured bye the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the th\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 2.1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\callbacks.py:535: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 2.0936\n",
      "Epoch 3/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 2.0795\n",
      "Epoch 4/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 2.0678\n",
      "Epoch 5/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 2.0564\n",
      "Epoch 6/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 2.0464\n",
      "Epoch 7/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 2.0365\n",
      "Epoch 8/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 2.0243\n",
      "Epoch 9/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 2.0146\n",
      "Epoch 10/50\n",
      "109310/109310 [==============================] - 821s 8ms/step - loss: 2.0097\n",
      "Epoch 11/50\n",
      "109310/109310 [==============================] - 821s 8ms/step - loss: 1.9978\n",
      "Epoch 12/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 1.9889\n",
      "Epoch 13/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9840\n",
      "Epoch 14/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9788\n",
      "Epoch 15/50\n",
      "109310/109310 [==============================] - 821s 8ms/step - loss: 1.9688\n",
      "Epoch 16/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9628\n",
      "Epoch 17/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9564\n",
      "Epoch 18/50\n",
      "109310/109310 [==============================] - 821s 8ms/step - loss: 1.9482\n",
      "Epoch 19/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9397\n",
      "Epoch 20/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9363\n",
      "Epoch 21/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.9309\n",
      "Epoch 22/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9291\n",
      "Epoch 23/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.9219\n",
      "Epoch 24/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 1.9166\n",
      "Epoch 25/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.9103\n",
      "Epoch 26/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9060\n",
      "Epoch 27/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.9029\n",
      "Epoch 28/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.8978\n",
      "Epoch 29/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 1.8936\n",
      "Epoch 30/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.8915\n",
      "Epoch 31/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.8834\n",
      "Epoch 32/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.8814\n",
      "Epoch 33/50\n",
      "109310/109310 [==============================] - 821s 8ms/step - loss: 1.8758\n",
      "Epoch 34/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.8753\n",
      "Epoch 35/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.8709\n",
      "Epoch 36/50\n",
      "109310/109310 [==============================] - 823s 8ms/step - loss: 1.8675\n",
      "Epoch 37/50\n",
      "109310/109310 [==============================] - 822s 8ms/step - loss: 1.8634\n",
      "Epoch 38/50\n",
      "109310/109310 [==============================] - 826s 8ms/step - loss: 1.8584\n",
      "Epoch 39/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.8602\n",
      "Epoch 40/50\n",
      "109310/109310 [==============================] - 824s 8ms/step - loss: 1.8527\n",
      "Epoch 41/50\n",
      "109310/109310 [==============================] - 832s 8ms/step - loss: 1.8536\n",
      "Epoch 42/50\n",
      "109310/109310 [==============================] - 833s 8ms/step - loss: 1.8477\n",
      "Epoch 43/50\n",
      "109310/109310 [==============================] - 828s 8ms/step - loss: 1.8459\n",
      "Epoch 44/50\n",
      "109310/109310 [==============================] - 830s 8ms/step - loss: 1.8421\n",
      "Epoch 45/50\n",
      "109310/109310 [==============================] - 830s 8ms/step - loss: 1.8408\n",
      "Epoch 46/50\n",
      "109310/109310 [==============================] - 878s 8ms/step - loss: 1.8361\n",
      "Epoch 47/50\n",
      "109310/109310 [==============================] - 848s 8ms/step - loss: 1.8363\n",
      "Epoch 48/50\n",
      "109310/109310 [==============================] - 864s 8ms/step - loss: 1.8305\n",
      "Epoch 49/50\n",
      "109310/109310 [==============================] - 874s 8ms/step - loss: 1.8286\n",
      "Epoch 50/50\n",
      "109310/109310 [==============================] - 963s 9ms/step - loss: 1.8293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b1a71db38>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=50, batch_size=50, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_1_input to have shape (100, 1) but got array with shape (101, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f285c332fd69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpred_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_to_char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring_mapped\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mfull_string\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_to_char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                              'argument.')\n\u001b[0;32m   1151\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jai dave\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    134\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_1_input to have shape (100, 1) but got array with shape (101, 1)"
     ]
    }
   ],
   "source": [
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"h)\\njerry: (to elaine) let me ask you a question.\\nelaine: mm-hm.\\njerry: you're a hostage, captured by the sare a cout of the cout and the sare a cout of the cout and the sare a cout of the cout and the sare a cout of the cout and the sare a cout of the cout and the sare a cout of the cout and the sare a cout of the cout and the sare a cout of the cout and the sare a cout of the cout and the sare a cout of the cout and the sare a cout of the cout and the sare a cout of the cout and the sare a cout\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
